{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Structures:\n",
    "- Lists\n",
    "- Dicts\n",
    "- Strings\n",
    "- Tuples\n",
    "- Sets\n",
    "\n",
    "## Lists:\n",
    "Sequence of elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d', 'b', 'c', 'b', 'a', ['d', 'e', 'f']]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append:\n",
    "my_list = ['d','b','c','b', 'a']\n",
    "my_list.append(['d', 'e', 'f'])\n",
    "my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list[-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d', 'b', 'c', 'b', 'a', 'd', 'e', 'f']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extend:\n",
    "my_list = ['d','b','c','b', 'a']\n",
    "my_list.extend(['d', 'e', 'f'])\n",
    "my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'b', 'c', 'd', 'd', 'e', 'f']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort:\n",
    "sorted_list = sorted(my_list)\n",
    "sorted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index:\n",
    "my_list = ['d','b','c','b', 'a']\n",
    "my_list.index('b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 15, 16]\n",
      "[11, 12, 13, 14, 15]\n",
      "[11, 13, 15]\n"
     ]
    }
   ],
   "source": [
    "# Slicing:\n",
    "# list[firstIndex:lastIndex:step]\n",
    "a = [11, 12, 13, 14, 15, 16, 17, 18]\n",
    "print a[3:6]\n",
    "print a[:5]\n",
    "print a[:5:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 14, 16, 18]\n"
     ]
    }
   ],
   "source": [
    "# List Comprehension:\n",
    "even = []\n",
    "for i in a:\n",
    "    if i % 2 == 0:\n",
    "        even.append(i)\n",
    "print even"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 14, 16, 18]\n"
     ]
    }
   ],
   "source": [
    "even2 = [i for i in a if i % 2 == 0]\n",
    "print even2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dicts:\n",
    "An unordered collection of (key, value) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys:  ['New York', 'Delhi', 'London', 'Montreal']\n",
      "Values:  [9, 19, 8, 2]\n"
     ]
    }
   ],
   "source": [
    "population = {'Montreal':2, 'Delhi':19, 'New York':9, 'London':8}\n",
    "print \"Keys: \", population.keys()\n",
    "print \"Values: \", population.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York's population: 9 million.\n",
      "Delhi's population: 19 million.\n",
      "London's population: 8 million.\n",
      "Montreal's population: 2 million.\n"
     ]
    }
   ],
   "source": [
    "for (key, val) in population.items():\n",
    "    print key + \"'s population: \" + str(val) + \" million.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print population['London']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SF'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-58e08196657f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'SF'"
     ]
    }
   ],
   "source": [
    "print population['SF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "pop = defaultdict(int) # Default value is 0\n",
    "pop['Montreal'] = 2\n",
    "pop['Delhi'] = 19\n",
    "print pop['Delhi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# No more key errors:\n",
    "print pop['SF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDK buddy\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Could also use Lambda in defaultdict:\n",
    "pop = defaultdict(lambda: 'IDK buddy')\n",
    "pop['Montreal'] = 2\n",
    "pop['Delhi'] = 19\n",
    "print pop['SF']\n",
    "\n",
    "\n",
    "# Lambda is for creating quick anonymous functions\n",
    "f = lambda x,y: x+y\n",
    "print f(4,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sets:\n",
    "An unordered collection of UNIQUE mutable elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = set([1, 2, 3, 4])\n",
    "b = set([3, 4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([1, 2, 3, 4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "print a.union(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([3, 4])\n"
     ]
    }
   ],
   "source": [
    "inter = a.intersection(b)\n",
    "print inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print inter.issubset(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([1, 2])\n"
     ]
    }
   ],
   "source": [
    "print a - b # a But Not b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fun Facts:\n",
    "- Ordering of Dictionaries and Sets is arbitrary, so you don't want to rely on them.\n",
    "- Lists, Dicts, Sets were all mutable.\n",
    "- Strings, Tuples are immutable.\n",
    "\n",
    "## Tuples:\n",
    "Sequence of elements, just like lists, but immutable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 18, 2385, 28, 5)\n"
     ]
    }
   ],
   "source": [
    "tup1 = (12, 18, 2385, 28, 5, 2, 17)\n",
    "tup2 = ('abc', 'xyz')\n",
    "\n",
    "print tup1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-af7a161c8ad2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Tuples are immutable:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtup1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "# Tuples are immutable:\n",
    "tup1[0] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 18, 2385, 28, 5, 2, 17, 'abc', 'xyz')\n"
     ]
    }
   ],
   "source": [
    "tup3 = tup1 + tup2\n",
    "print tup3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We usually combine these data structures: List of dictionaries, List of tuples etc.\n",
    "# Tuples are usable as a dictionary keys, while lists are not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a dummy string\n",
      "THIS IS A DUMMY STRING\n",
      "tHIS IS A DUMMY STRING\n"
     ]
    }
   ],
   "source": [
    "mystr = \"This is a dummy string\"\n",
    "print mystr.lower()\n",
    "print mystr.upper()\n",
    "print mystr.swapcase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print mystr.endswith('ing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print mystr.startswith('This')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print mystr.find('is')            # returns start index of 'is' first occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print mystr.find('is', 4)         # starting at index 4, returns start index of 'is' first occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"    hey, what's up?   \""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usually the text data has noise (extra whitespaces):\n",
    "mystr = \"    hey, what's up?   \"\n",
    "mystr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"    hey, what's up?\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystr.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hey, what's up?   \""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystr.lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hey, what's up?\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystr.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', ' is a', ' useful method']\n"
     ]
    }
   ],
   "source": [
    "mystr = \"This; is a; useful method\"\n",
    "str_list = mystr.split(';')\n",
    "print str_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This; is a; useful method\n"
     ]
    }
   ],
   "source": [
    "print ';'.join(str_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickling results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# An easy way to store intermediate/final outputs. But only do it when your work is specific to Python.\n",
    "# Cross-language compatibility is not guaranteed.\n",
    "import pickle\n",
    "\n",
    "path = './important.pickle'\n",
    "with open(path, 'wb') as f:\n",
    "    pickle.dump(str_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', ' is a', ' useful method']\n"
     ]
    }
   ],
   "source": [
    "with open(path, 'rb') as f:\n",
    "    a = pickle.load(f)\n",
    "print a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's work through a Spam Detection problem:\n",
    "- I uploaded a toy dataset here: https://github.com/sunyam/Python-Tutorial/tree/master/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports:\n",
    "import os\n",
    "import random\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of emails:  611\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset:\n",
    "all_emails = []\n",
    "\n",
    "def load_dataset(path):\n",
    "    # Loading spam-emails:\n",
    "    for email in os.listdir(path+'spam'):\n",
    "        with open(path+'spam' + '/' + email, 'r') as f:\n",
    "            content = f.read()\n",
    "            all_emails.append((content, \"spam\"))\n",
    "\n",
    "    # Loading ham-emails:\n",
    "    for email in os.listdir(path+'ham'):\n",
    "        f = open(path+'ham' + os.sep + email, 'r')\n",
    "        content = f.read()\n",
    "        all_emails.append((content, \"ham\"))\n",
    "        f.close()\n",
    "\n",
    "    print \"Total number of emails: \", len(all_emails)\n",
    "\n",
    "    \n",
    "    \n",
    "path = './dataset/'\n",
    "# 286 Spam emails; 325 Ham emails.\n",
    "load_dataset(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Subject: advs\\r\\ngreetings ,\\r\\ni am benedicta lindiwe hendricks ( mrs ) of rsa . i am writing\\r\\nthis letter to you with the hope that you will be kind enough\\r\\nto assist my family .\\r\\nif this means of communication is not acceptable to you please\\r\\naccept my apologies as it is the only available and resourceful\\r\\nmeans for me right now .\\r\\nmy children and i are in need of your assistance and we sincerely\\r\\npray and hope that you will be able to attend to our request .\\r\\nif there is the possibility that you will be able to help us do\\r\\nkindly let me know by return mail so that i can tell you about\\r\\nour humble request .\\r\\nthank for your understanding .\\r\\nbenedicta lindiwe hendricks ( mrs ) .\\r\\nplease reply to this email address ; heno 0 @ katamail . com', 'spam'), ('Subject: whats new in summer ? bawled\\r\\ncarolyn regretful watchfully procrustes godly\\r\\nsummer 2004 was too hot for the software manufacturers .\\r\\nno wonder ! as the prices were reduced in 3 - 4 times .\\r\\nthis was caused by the software glut on the world market .\\r\\non the other hand the user who were not able or just had\\r\\nno time to update their software now have the possibility\\r\\nto do this almost free of charge .\\r\\nread the whole article :\\r\\nyear 2004 . sotware prices fall down .\\r\\n\\xe2 \\xa9 peter lemelman\\r\\nonerous reclaimers remunerate lounsbury dictate\\r\\ncosted continued snooping digression rhine\\r\\ninseminate tilts instructs rejoice switchman\\r\\nstomaching hurtling brent gunners tortoises\\r\\n', 'spam')]\n"
     ]
    }
   ],
   "source": [
    "print all_emails[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanUp(text, custom_stopwords=[]):\n",
    "    # Initilaise Lemmatizer object:\n",
    "    lemm = WordNetLemmatizer()\n",
    "    \n",
    "    # Load NLTK stopwords:\n",
    "    my_stopwords = stopwords.words('english') + custom_stopwords\n",
    "    \n",
    "    clean_text = ''\n",
    "    \n",
    "    words = word_tokenize(unicode(text, errors='ignore')) # word_tokenize() takes care of stripping too.\n",
    "    \n",
    "    for word in words:\n",
    "        w = lemm.lemmatize(word.lower())\n",
    "        if w not in my_stopwords and len(w)>2:\n",
    "            clean_text += w + ' '\n",
    "    \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_emails_with_labels = []\n",
    "for (email, label) in all_emails:\n",
    "    clean_email = cleanUp(email, ['subject'])\n",
    "    clean_emails_with_labels.append((clean_email, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'advs greeting benedicta lindiwe hendricks rsa writing letter hope kind enough assist family mean communication acceptable please accept apology available resourceful mean right child need assistance sincerely pray hope able attend request possibility able help kindly let know return mail tell humble request thank understanding benedicta lindiwe hendricks please reply email address heno katamail com ', 'spam'), (u'whats new summer bawled carolyn regretful watchfully procrustes godly summer 2004 hot software manufacturer wonder price reduced time caused software glut world market hand user able time update software possibility almost free charge read whole article year 2004 sotware price fall peter lemelman onerous reclaimers remunerate lounsbury dictate costed continued snooping digression rhine inseminate tilt instructs rejoice switchman stomaching hurtling brent gunner tortoise ', 'spam')]\n"
     ]
    }
   ],
   "source": [
    "print clean_emails_with_labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(clean_emails_with_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'scan show infected adware oxok infected spyware adware get free adware scan removal download get worse http becw myspyerase biz 111213 still infected phonology furthermore denude remembrance octal monte cicada collegiate wave crematory categoric knight ', 'spam'), (u'tech service louise arrangement without dotted line reporting relationship member ena tech service group wholesale group otherwise role somewhat superfluous cloudy best still achieve result brian working together brian louise kitchen 2001 brian redmond hou ect ect tech service point dotted line like joe deffner dotted line andy fastow see getting worried dotted line notice one alternative mentioned leaving today reporting managing relationship brian think louise brian redmond 2001 louise kitchen hou ect ect tech service louise brief chat mark regarding plan enron wholesale tech service understand see ena tech service group reporting brian stanley dotted line basis order keep group coordinated may want first discus sell reporting relationship origination unit fear another sell organizational structure member ena tech service group concerned may loose top engineer resist organizationally tied two possible alternative arrangement ena tech service group remains ena development engineering organization regionalized report solid line origination group keep ena tech service group lean mean somewhat independent wholesale tech service group bob virgo mike coleman would report presto durhan wayne mayes team would report calger mike coleman would report max would help support esa nick cocavessis would support gas liquid business ron blackham would support enron south america brian stanley group would seen technical resource base draw friendly check technical assumption used pro formas brian stanley group would provide review enron america dash keep ena tech service group becoming aggressive assumption whereas brian group tend conservative role risk manager another alternative create broader role commercial investment asset management group dick spoke unit would combine skill set restructuring group tech service group would technical responsibility ena transaction throughout life cycle would commercial responsibility investment asset longer strategic ongoing financial value origination group specifically investment asset projected earn cost capital investment asset little strategic value troubled asset position investment required significant time attention beyond origination group willing spend suggestion group would use brian stanley organization resource base draw needed basis however would formal reporting relationship let discus brian ', 'ham')]\n"
     ]
    }
   ],
   "source": [
    "print clean_emails_with_labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A great Jupyter feature: Shift+Tab to see function arguments + documentation.\n",
    "# train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of emails:  611\n",
      "Labels:  611\n"
     ]
    }
   ],
   "source": [
    "# We need to pass email-text only to the CountVectorizer\n",
    "emails = []\n",
    "labels = []\n",
    "\n",
    "for (email, label) in clean_emails_with_labels:\n",
    "    emails.append(email)\n",
    "    labels.append(label)\n",
    "\n",
    "#list(zip(*clean_emails_with_labels)[0]) # also gives you \"emails\"\n",
    "#list(zip(*clean_emails_with_labels)[1]) # also gives you \"labels\"\n",
    "\n",
    "print \"Number of emails: \", len(emails)\n",
    "print \"Labels: \", len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the dataset:\n",
    "x_train, x_test, y_train, y_test = train_test_split(emails, labels, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(409, 13440)\n",
      "409\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer:\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit to our training data\n",
    "X = vectorizer.fit_transform(x_train)\n",
    "\n",
    "print X.shape\n",
    "print len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Naive Bayes:\n",
    "nb_detector = MultinomialNB()\n",
    "nb_detector.fit(X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'spam']\n"
     ]
    }
   ],
   "source": [
    "# Just randomly testing the model:\n",
    "test = [u'article powerits online trading platform please find attached article european electricity report september 2001 kind regard sarimah black', \n",
    "        u'need help marriage hello vlgr professi nal per dose vlgr soft per dose generc vlgr per dose clls per dose clls soft per dose sinneth wrongeth soul hate love death son let depart thine eye keep sound wisdom discretion say hated instruction heart despised reproof house righteous much treasure revenue wicked trouble better little righteousness great revenue without right']\n",
    "\n",
    "x_te = vectorizer.transform(test)\n",
    "print nb_detector.predict(x_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "['ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'spam' 'ham' 'spam'\n",
      " 'ham' 'ham' 'spam' 'ham' 'ham' 'spam' 'spam' 'ham' 'spam' 'ham' 'spam'\n",
      " 'ham' 'ham' 'spam' 'spam' 'ham' 'spam' 'spam' 'ham' 'ham' 'ham' 'spam'\n",
      " 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham'\n",
      " 'ham' 'ham' 'spam' 'spam' 'ham' 'ham' 'spam' 'ham' 'ham' 'spam' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'spam' 'ham' 'spam' 'spam'\n",
      " 'spam' 'spam' 'ham' 'ham' 'ham' 'spam' 'ham' 'spam' 'spam' 'spam' 'spam'\n",
      " 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'spam'\n",
      " 'spam' 'spam' 'ham' 'spam' 'ham' 'ham' 'spam' 'spam' 'spam' 'ham' 'ham'\n",
      " 'ham' 'ham' 'spam' 'ham' 'spam' 'spam' 'spam' 'ham' 'ham' 'spam' 'ham'\n",
      " 'ham' 'ham' 'spam' 'ham' 'ham' 'spam' 'ham' 'ham' 'spam' 'spam' 'spam'\n",
      " 'spam' 'ham' 'ham' 'ham' 'spam' 'ham' 'spam' 'spam' 'ham' 'spam' 'ham'\n",
      " 'spam' 'ham' 'ham' 'ham' 'spam' 'ham' 'spam' 'spam' 'spam' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'spam' 'ham' 'spam' 'spam'\n",
      " 'spam' 'spam' 'ham' 'ham' 'spam' 'spam' 'spam' 'ham' 'spam' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'spam' 'spam' 'spam' 'spam'\n",
      " 'ham' 'ham' 'spam' 'ham' 'spam' 'spam' 'ham' 'ham' 'spam' 'ham' 'ham'\n",
      " 'ham' 'spam' 'spam' 'spam' 'spam' 'spam' 'spam' 'ham' 'ham' 'spam' 'ham'\n",
      " 'ham' 'ham' 'ham']\n"
     ]
    }
   ],
   "source": [
    "# Testing properly with test-set:\n",
    "X_test = vectorizer.transform(x_test)\n",
    "y_pred = nb_detector.predict(X_test)\n",
    "print X_test.toarray()\n",
    "print y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9851485148514851\n"
     ]
    }
   ],
   "source": [
    "# Calculate Accuracy:\n",
    "print \"Accuracy: \", sklearn.metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 84   2]\n",
      " [  1 115]]\n"
     ]
    }
   ],
   "source": [
    "# True rows; Predicted Columns [\"True\" left; \"Predict\" top]\n",
    "print sklearn.metrics.confusion_matrix(y_test, y_pred, labels=[\"spam\", \"ham\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc. stuff:\n",
    "\n",
    "#### Reading/Writing to files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./blah.txt', 'w') as f:\n",
    "    f.write(\"Hey this is line1.\\nThis is 2.\\nOnto line 3 now.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey this is line1.\n",
      "This is 2.\n",
      "Onto line 3 now.\n"
     ]
    }
   ],
   "source": [
    "with open('./blah.txt', 'r') as f:\n",
    "    print f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hey this is line1.\\n', 'This is 2.\\n', 'Onto line 3 now.']\n"
     ]
    }
   ],
   "source": [
    "with open('./blah.txt', 'r') as f:\n",
    "    print f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>Population</th>\n",
       "      <th>Area (sq. mi.)</th>\n",
       "      <th>Pop. Density (per sq. mi.)</th>\n",
       "      <th>Coastline (coast/area ratio)</th>\n",
       "      <th>Net migration</th>\n",
       "      <th>Infant mortality (per 1000 births)</th>\n",
       "      <th>GDP ($ per capita)</th>\n",
       "      <th>Literacy (%)</th>\n",
       "      <th>Phones (per 1000)</th>\n",
       "      <th>Arable (%)</th>\n",
       "      <th>Crops (%)</th>\n",
       "      <th>Other (%)</th>\n",
       "      <th>Climate</th>\n",
       "      <th>Birthrate</th>\n",
       "      <th>Deathrate</th>\n",
       "      <th>Agriculture</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>ASIA (EX. NEAR EAST)</td>\n",
       "      <td>31056997</td>\n",
       "      <td>647500</td>\n",
       "      <td>48,0</td>\n",
       "      <td>0,00</td>\n",
       "      <td>23,06</td>\n",
       "      <td>163,07</td>\n",
       "      <td>700.0</td>\n",
       "      <td>36,0</td>\n",
       "      <td>3,2</td>\n",
       "      <td>12,13</td>\n",
       "      <td>0,22</td>\n",
       "      <td>87,65</td>\n",
       "      <td>1</td>\n",
       "      <td>46,6</td>\n",
       "      <td>20,34</td>\n",
       "      <td>0,38</td>\n",
       "      <td>0,24</td>\n",
       "      <td>0,38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>EASTERN EUROPE</td>\n",
       "      <td>3581655</td>\n",
       "      <td>28748</td>\n",
       "      <td>124,6</td>\n",
       "      <td>1,26</td>\n",
       "      <td>-4,93</td>\n",
       "      <td>21,52</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>86,5</td>\n",
       "      <td>71,2</td>\n",
       "      <td>21,09</td>\n",
       "      <td>4,42</td>\n",
       "      <td>74,49</td>\n",
       "      <td>3</td>\n",
       "      <td>15,11</td>\n",
       "      <td>5,22</td>\n",
       "      <td>0,232</td>\n",
       "      <td>0,188</td>\n",
       "      <td>0,579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "      <td>32930091</td>\n",
       "      <td>2381740</td>\n",
       "      <td>13,8</td>\n",
       "      <td>0,04</td>\n",
       "      <td>-0,39</td>\n",
       "      <td>31</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>70,0</td>\n",
       "      <td>78,1</td>\n",
       "      <td>3,22</td>\n",
       "      <td>0,25</td>\n",
       "      <td>96,53</td>\n",
       "      <td>1</td>\n",
       "      <td>17,14</td>\n",
       "      <td>4,61</td>\n",
       "      <td>0,101</td>\n",
       "      <td>0,6</td>\n",
       "      <td>0,298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>OCEANIA</td>\n",
       "      <td>57794</td>\n",
       "      <td>199</td>\n",
       "      <td>290,4</td>\n",
       "      <td>58,29</td>\n",
       "      <td>-20,71</td>\n",
       "      <td>9,27</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>97,0</td>\n",
       "      <td>259,5</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>22,46</td>\n",
       "      <td>3,27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>WESTERN EUROPE</td>\n",
       "      <td>71201</td>\n",
       "      <td>468</td>\n",
       "      <td>152,1</td>\n",
       "      <td>0,00</td>\n",
       "      <td>6,6</td>\n",
       "      <td>4,05</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>100,0</td>\n",
       "      <td>497,2</td>\n",
       "      <td>2,22</td>\n",
       "      <td>0</td>\n",
       "      <td>97,78</td>\n",
       "      <td>3</td>\n",
       "      <td>8,71</td>\n",
       "      <td>6,25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Country                               Region  Population  \\\n",
       "0     Afghanistan         ASIA (EX. NEAR EAST)             31056997   \n",
       "1         Albania   EASTERN EUROPE                          3581655   \n",
       "2         Algeria   NORTHERN AFRICA                        32930091   \n",
       "3  American Samoa   OCEANIA                                   57794   \n",
       "4         Andorra   WESTERN EUROPE                            71201   \n",
       "\n",
       "   Area (sq. mi.) Pop. Density (per sq. mi.) Coastline (coast/area ratio)  \\\n",
       "0          647500                       48,0                         0,00   \n",
       "1           28748                      124,6                         1,26   \n",
       "2         2381740                       13,8                         0,04   \n",
       "3             199                      290,4                        58,29   \n",
       "4             468                      152,1                         0,00   \n",
       "\n",
       "  Net migration Infant mortality (per 1000 births)  GDP ($ per capita)  \\\n",
       "0         23,06                             163,07               700.0   \n",
       "1         -4,93                              21,52              4500.0   \n",
       "2         -0,39                                 31              6000.0   \n",
       "3        -20,71                               9,27              8000.0   \n",
       "4           6,6                               4,05             19000.0   \n",
       "\n",
       "  Literacy (%) Phones (per 1000) Arable (%) Crops (%) Other (%) Climate  \\\n",
       "0         36,0               3,2      12,13      0,22     87,65       1   \n",
       "1         86,5              71,2      21,09      4,42     74,49       3   \n",
       "2         70,0              78,1       3,22      0,25     96,53       1   \n",
       "3         97,0             259,5         10        15        75       2   \n",
       "4        100,0             497,2       2,22         0     97,78       3   \n",
       "\n",
       "  Birthrate Deathrate Agriculture Industry Service  \n",
       "0      46,6     20,34        0,38     0,24    0,38  \n",
       "1     15,11      5,22       0,232    0,188   0,579  \n",
       "2     17,14      4,61       0,101      0,6   0,298  \n",
       "3     22,46      3,27         NaN      NaN     NaN  \n",
       "4      8,71      6,25         NaN      NaN     NaN  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = './countries-of-the world.csv'\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country                               227\n",
       "Region                                 11\n",
       "Population                            227\n",
       "Area (sq. mi.)                        226\n",
       "Pop. Density (per sq. mi.)            219\n",
       "Coastline (coast/area ratio)          151\n",
       "Net migration                         157\n",
       "Infant mortality (per 1000 births)    220\n",
       "GDP ($ per capita)                    130\n",
       "Literacy (%)                          140\n",
       "Phones (per 1000)                     214\n",
       "Arable (%)                            203\n",
       "Crops (%)                             162\n",
       "Other (%)                             209\n",
       "Climate                                 6\n",
       "Birthrate                             220\n",
       "Deathrate                             201\n",
       "Agriculture                           150\n",
       "Industry                              155\n",
       "Service                               167\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
