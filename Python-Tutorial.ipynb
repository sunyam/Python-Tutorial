{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Structures:\n",
    "- Lists\n",
    "- Dicts\n",
    "- Strings\n",
    "- Tuples\n",
    "- Sets\n",
    "\n",
    "## Lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d', 'b', 'c', 'b', 'a', ['d', 'e', 'f']]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append:\n",
    "my_list = ['d','b','c','b', 'a']\n",
    "my_list.append(['d', 'e', 'f'])\n",
    "my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list[-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d', 'b', 'c', 'b', 'a', 'd', 'e', 'f']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extend:\n",
    "my_list = ['d','b','c','b', 'a']\n",
    "my_list.extend(['d', 'e', 'f'])\n",
    "my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'b', 'c', 'd', 'd', 'e', 'f']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort:\n",
    "sorted_list = sorted(my_list)\n",
    "sorted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index:\n",
    "my_list = ['d','b','c','b', 'a']\n",
    "my_list.index('b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 15, 16]\n",
      "[11, 12, 13, 14, 15]\n",
      "[11, 13, 15]\n"
     ]
    }
   ],
   "source": [
    "# Slicing:\n",
    "# list[firstIndex:lastIndex:step]\n",
    "a = [11, 12, 13, 14, 15, 16, 17, 18]\n",
    "print a[3:6]\n",
    "print a[:5]\n",
    "print a[:5:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 14, 16, 18]\n"
     ]
    }
   ],
   "source": [
    "# List Comprehension:\n",
    "even = []\n",
    "for i in a:\n",
    "    if i % 2 == 0:\n",
    "        even.append(i)\n",
    "print even"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 14, 16, 18]\n"
     ]
    }
   ],
   "source": [
    "even2 = [i for i in a if i % 2 == 0]\n",
    "print even2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dicts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys:  ['New York', 'Delhi', 'London', 'Montreal']\n",
      "Values:  [9, 19, 8, 2]\n"
     ]
    }
   ],
   "source": [
    "population = {'Montreal':2, 'Delhi':19, 'New York':9, 'London':8}\n",
    "print \"Keys: \", population.keys()\n",
    "print \"Values: \", population.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York's population: 9 million.\n",
      "Delhi's population: 19 million.\n",
      "London's population: 8 million.\n",
      "Montreal's population: 2 million.\n"
     ]
    }
   ],
   "source": [
    "for (key, val) in population.items():\n",
    "    print key + \"'s population: \" + str(val) + \" million.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print population['London']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SF'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-58e08196657f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'SF'"
     ]
    }
   ],
   "source": [
    "print population['SF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "pop = defaultdict(int) # Default value is 0\n",
    "pop['Montreal'] = 2\n",
    "pop['Delhi'] = 19\n",
    "print pop['Delhi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# No more key errors:\n",
    "print pop['SF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDK buddy\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Could also use Lambda in defaultdict:\n",
    "pop = defaultdict(lambda: 'IDK buddy')\n",
    "pop['Montreal'] = 2\n",
    "pop['Delhi'] = 19\n",
    "print pop['SF']\n",
    "\n",
    "\n",
    "# Lambda is for creating quick anonymous functions\n",
    "f = lambda x,y: x+y\n",
    "print f(4,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = set([1, 2, 3, 4])\n",
    "b = set([3, 4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([1, 2, 3, 4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "print a.union(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([3, 4])\n"
     ]
    }
   ],
   "source": [
    "inter = a.intersection(b)\n",
    "print inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print inter.issubset(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([1, 2])\n"
     ]
    }
   ],
   "source": [
    "print a - b # a But Not b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fun Facts:\n",
    "- Ordering of Dictionaries and Sets is arbitrary, so you don't want to rely on them.\n",
    "- Lists, Dicts, Sets were all mutable.\n",
    "- Strings, Tuples are immutable.\n",
    "\n",
    "## Tuples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 18, 2385, 28, 5)\n"
     ]
    }
   ],
   "source": [
    "tup1 = (12, 18, 2385, 28, 5, 2, 17)\n",
    "tup2 = ('abc', 'xyz')\n",
    "\n",
    "print tup1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-af7a161c8ad2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Tuples are immutable:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtup1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "# Tuples are immutable:\n",
    "tup1[0] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 18, 2385, 28, 5, 2, 17, 'abc', 'xyz')\n"
     ]
    }
   ],
   "source": [
    "tup3 = tup1 + tup2\n",
    "print tup3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We usually combine these data structures: List of dictionaries, List of tuples etc.\n",
    "# Tuples are usable as a dictionary keys, while lists are not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a dummy string\n",
      "THIS IS A DUMMY STRING\n",
      "tHIS IS A DUMMY STRING\n"
     ]
    }
   ],
   "source": [
    "mystr = \"This is a dummy string\"\n",
    "print mystr.lower()\n",
    "print mystr.upper()\n",
    "print mystr.swapcase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print mystr.endswith('ing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print mystr.startswith('This')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print mystr.find('is')            # returns start index of 'is' first occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print mystr.find('is', 4)         # starting at index 4, returns start index of 'is' first occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"    hey, what's up?   \""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usually the text data has noise (extra whitespaces):\n",
    "mystr = \"    hey, what's up?   \"\n",
    "mystr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"    hey, what's up?\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystr.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hey, what's up?   \""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystr.lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hey, what's up?\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystr.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', ' is a', ' useful method']\n"
     ]
    }
   ],
   "source": [
    "mystr = \"This; is a; useful method\"\n",
    "str_list = mystr.split(';')\n",
    "print str_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This; is a; useful method\n"
     ]
    }
   ],
   "source": [
    "print ';'.join(str_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickling results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An easy way to store intermediate/final outputs. But only do it when your work is specific to Python.\n",
    "# Cross-language compatibility is not guaranteed.\n",
    "import pickle\n",
    "\n",
    "path = './important.pickle'\n",
    "with open(path, 'wb') as f:\n",
    "    pickle.dump(str_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', ' is a', ' useful method']\n"
     ]
    }
   ],
   "source": [
    "with open(path, 'rb') as f:\n",
    "    a = pickle.load(f)\n",
    "print a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's work through a Spam Detection problem:\n",
    "- I uploaded a toy dataset here: https://github.com/sunyam/Python-Tutorial/tree/master/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports:\n",
    "import os\n",
    "import random\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of emails:  611\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset:\n",
    "all_emails = []\n",
    "\n",
    "def load_dataset(path):\n",
    "    # Loading spam-emails:\n",
    "    for email in os.listdir(path+'spam'):\n",
    "        with open(path+'spam' + '/' + email, 'r') as f:\n",
    "            content = f.read()\n",
    "            all_emails.append((content, \"spam\"))\n",
    "\n",
    "    # Loading ham-emails:\n",
    "    for email in os.listdir(path+'ham'):\n",
    "        f = open(path+'ham' + os.sep + email, 'r')\n",
    "        content = f.read()\n",
    "        all_emails.append((content, \"ham\"))\n",
    "        f.close()\n",
    "\n",
    "    print \"Total number of emails: \", len(all_emails)\n",
    "\n",
    "    \n",
    "    \n",
    "path = './dataset/'\n",
    "# 286 Spam emails; 325 Ham emails.\n",
    "load_dataset(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Subject: advs\\r\\ngreetings ,\\r\\ni am benedicta lindiwe hendricks ( mrs ) of rsa . i am writing\\r\\nthis letter to you with the hope that you will be kind enough\\r\\nto assist my family .\\r\\nif this means of communication is not acceptable to you please\\r\\naccept my apologies as it is the only available and resourceful\\r\\nmeans for me right now .\\r\\nmy children and i are in need of your assistance and we sincerely\\r\\npray and hope that you will be able to attend to our request .\\r\\nif there is the possibility that you will be able to help us do\\r\\nkindly let me know by return mail so that i can tell you about\\r\\nour humble request .\\r\\nthank for your understanding .\\r\\nbenedicta lindiwe hendricks ( mrs ) .\\r\\nplease reply to this email address ; heno 0 @ katamail . com', 'spam'), ('Subject: whats new in summer ? bawled\\r\\ncarolyn regretful watchfully procrustes godly\\r\\nsummer 2004 was too hot for the software manufacturers .\\r\\nno wonder ! as the prices were reduced in 3 - 4 times .\\r\\nthis was caused by the software glut on the world market .\\r\\non the other hand the user who were not able or just had\\r\\nno time to update their software now have the possibility\\r\\nto do this almost free of charge .\\r\\nread the whole article :\\r\\nyear 2004 . sotware prices fall down .\\r\\n\\xe2 \\xa9 peter lemelman\\r\\nonerous reclaimers remunerate lounsbury dictate\\r\\ncosted continued snooping digression rhine\\r\\ninseminate tilts instructs rejoice switchman\\r\\nstomaching hurtling brent gunners tortoises\\r\\n', 'spam')]\n"
     ]
    }
   ],
   "source": [
    "print all_emails[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanUp(text, custom_stopwords=[]):\n",
    "    # Initilaise Lemmatizer object:\n",
    "    lemm = WordNetLemmatizer()\n",
    "    \n",
    "    # Load NLTK stopwords:\n",
    "    my_stopwords = stopwords.words('english') + custom_stopwords\n",
    "    \n",
    "    clean_text = ''\n",
    "    \n",
    "    words = word_tokenize(unicode(text, errors='ignore')) # word_tokenize() takes care of stripping too.\n",
    "    \n",
    "    for word in words:\n",
    "        w = lemm.lemmatize(word.lower())\n",
    "        if w not in my_stopwords and len(w)>2:\n",
    "            clean_text += w + ' '\n",
    "    \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_emails_with_labels = []\n",
    "for (email, label) in all_emails:\n",
    "    clean_email = cleanUp(email, ['subject'])\n",
    "    clean_emails_with_labels.append((clean_email, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'advs greeting benedicta lindiwe hendricks rsa writing letter hope kind enough assist family mean communication acceptable please accept apology available resourceful mean right child need assistance sincerely pray hope able attend request possibility able help kindly let know return mail tell humble request thank understanding benedicta lindiwe hendricks please reply email address heno katamail com ', 'spam'), (u'whats new summer bawled carolyn regretful watchfully procrustes godly summer 2004 hot software manufacturer wonder price reduced time caused software glut world market hand user able time update software possibility almost free charge read whole article year 2004 sotware price fall peter lemelman onerous reclaimers remunerate lounsbury dictate costed continued snooping digression rhine inseminate tilt instructs rejoice switchman stomaching hurtling brent gunner tortoise ', 'spam')]\n"
     ]
    }
   ],
   "source": [
    "print clean_emails_with_labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(clean_emails_with_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'hello rich resume job service job small tel 408 482 2102 rysio yahoo com wiring installation hand electrical installation perform fitting mounting laying cable commercial industrial residential new existing building power supply light plug receptacle panel fuse box emergency generator wiring testing transformer power line conduit layout bending mounting parking lighting lamp switch post grocery story hardware story restaurant residential housing area computer business fast food unit installation building low voltage office home yard patio parking volt audio video equipment computer monitoring video control backup tape set mounting electro optical assembly subsystem power supply switch motion sensor alarm fire safety system install european standard fiber optic system plc setup motion management master control center machine process control computer dsl internet home net mail set firewall software hardware fax modem cable modem cable sat dish install help support solar project solar panel sun tracker power supply testing troubleshooting analyzing component level camera security system sensor safety fire sprinkler traffic monitoring door control telephone network move open travel home grounding delivery cable rod external wall partial whole house tel 408 482 2102 rysio yahoo com mechanical electro mechanical design quote supply estimating data base part list network sketch one line diagram title support build drawing power calculation energy audit support analyzing commissioning green building environmental energy system electrical mechanical project job small job big permanent preferred unsubscribe list send line unsubscribe linux kernel body message majordomo vger kernel org majordomo info http vger kernel org majordomo info html please read faq http www tux org lkml ', 'spam'), (u'cinergy left message michael call waiting regard delainey forwarded david delainey hou 2001 miller ect 2001 david delainey hou louise kitchen hou ect ect cinergy dave quick update appears art vacation week obviously concerned issue still waiting hear back david tang see want one guy plant tomorrow could get ferc approval day last real deal let know cyrus hook thanks ', 'ham')]\n"
     ]
    }
   ],
   "source": [
    "print clean_emails_with_labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A great Jupyter feature: Shift+Tab to see function arguments + documentation.\n",
    "# train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of emails:  611\n",
      "Labels:  611\n"
     ]
    }
   ],
   "source": [
    "# We need to pass email-text only to the CountVectorizer\n",
    "emails = []\n",
    "labels = []\n",
    "\n",
    "for (email, label) in clean_emails_with_labels:\n",
    "    emails.append(email)\n",
    "    labels.append(label)\n",
    "\n",
    "#list(zip(*clean_emails_with_labels)[0]) # also gives you \"emails\"\n",
    "#list(zip(*clean_emails_with_labels)[1]) # also gives you \"labels\"\n",
    "\n",
    "print \"Number of emails: \", len(emails)\n",
    "print \"Labels: \", len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the dataset:\n",
    "x_train, x_test, y_train, y_test = train_test_split(emails, labels, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(409, 13251)\n",
      "409\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer:\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit to our training data\n",
    "X = vectorizer.fit_transform(x_train)\n",
    "\n",
    "print X.shape\n",
    "print len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Naive Bayes:\n",
    "nb_detector = MultinomialNB()\n",
    "nb_detector.fit(X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'spam']\n"
     ]
    }
   ],
   "source": [
    "# Just randomly testing the model:\n",
    "test = [u'article powerits online trading platform please find attached article european electricity report september 2001 kind regard sarimah black', \n",
    "        u'need help marriage hello vlgr professi nal per dose vlgr soft per dose generc vlgr per dose clls per dose clls soft per dose sinneth wrongeth soul hate love death son let depart thine eye keep sound wisdom discretion say hated instruction heart despised reproof house righteous much treasure revenue wicked trouble better little righteousness great revenue without right']\n",
    "\n",
    "x_te = vectorizer.transform(test)\n",
    "print nb_detector.predict(x_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "['ham' 'spam' 'ham' 'ham' 'spam' 'spam' 'spam' 'spam' 'spam' 'ham' 'ham'\n",
      " 'spam' 'ham' 'spam' 'ham' 'spam' 'ham' 'ham' 'ham' 'spam' 'spam' 'ham'\n",
      " 'ham' 'ham' 'spam' 'ham' 'ham' 'spam' 'ham' 'spam' 'ham' 'ham' 'spam'\n",
      " 'spam' 'ham' 'spam' 'spam' 'ham' 'spam' 'ham' 'spam' 'ham' 'ham' 'ham'\n",
      " 'spam' 'ham' 'spam' 'spam' 'ham' 'spam' 'spam' 'ham' 'spam' 'spam' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'spam' 'ham' 'spam' 'spam' 'spam'\n",
      " 'spam' 'spam' 'ham' 'spam' 'spam' 'ham' 'spam' 'ham' 'ham' 'ham' 'spam'\n",
      " 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'spam' 'spam' 'spam'\n",
      " 'ham' 'spam' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'spam' 'spam' 'spam' 'ham' 'spam'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'spam' 'ham'\n",
      " 'spam' 'spam' 'ham' 'spam' 'ham' 'spam' 'spam' 'ham' 'spam' 'spam' 'spam'\n",
      " 'spam' 'ham' 'spam' 'ham' 'spam' 'spam' 'ham' 'ham' 'spam' 'ham' 'ham'\n",
      " 'ham' 'ham' 'spam' 'spam' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham'\n",
      " 'spam' 'ham' 'ham' 'ham' 'ham' 'spam' 'spam' 'ham' 'spam' 'ham' 'spam'\n",
      " 'ham' 'spam' 'spam' 'spam' 'ham' 'ham' 'spam' 'ham' 'spam' 'spam' 'ham'\n",
      " 'spam' 'spam' 'spam' 'ham' 'spam' 'spam' 'ham' 'spam' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'spam' 'spam' 'spam' 'spam' 'ham' 'ham' 'spam' 'ham' 'ham'\n",
      " 'spam' 'spam' 'spam' 'ham']\n"
     ]
    }
   ],
   "source": [
    "# Testing properly with test-set:\n",
    "X_test = vectorizer.transform(x_test)\n",
    "y_pred = nb_detector.predict(X_test)\n",
    "print X_test.toarray()\n",
    "print y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9801980198019802\n"
     ]
    }
   ],
   "source": [
    "# Calculate Accuracy:\n",
    "print \"Accuracy: \", sklearn.metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 94   4]\n",
      " [  0 104]]\n"
     ]
    }
   ],
   "source": [
    "# True rows; Predicted Columns [\"True\" left; \"Predict\" top]\n",
    "print sklearn.metrics.confusion_matrix(y_test, y_pred, labels=[\"spam\", \"ham\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
